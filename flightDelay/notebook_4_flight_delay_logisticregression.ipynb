{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"notebook_4_flight_delay_logisticregression.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"python352","language":"python","name":"python352"}},"cells":[{"metadata":{"id":"MwngwnyQLxb4","colab_type":"text"},"cell_type":"markdown","source":["# 0 Imports and helper functions"]},{"metadata":{"id":"SrzCM8CTLxb5","colab_type":"text"},"cell_type":"markdown","source":["https://gallery.azure.ai/Experiment/837e2095ce784f1ba5ac623a60232027"]},{"metadata":{"id":"GjJbEpzrLxb6","colab_type":"code","colab":{}},"cell_type":"code","source":["import sklearn\n","import pandas as pd\n","from sklearn import tree\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import time\n","from sklearn.metrics import roc_curve, auc\n","import json\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y-pD4GKSLxcF","colab_type":"text"},"cell_type":"markdown","source":["# 1 Loading the data"]},{"metadata":{"id":"BjTEPQQxL681","colab_type":"code","colab":{}},"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t7yj-Z4L2Elp","colab_type":"code","colab":{}},"cell_type":"code","source":["# delays = pd.read_csv(\"/content/drive/My Drive/xylosai/flightDelay/FlightDelaysData.csv\",header=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f16oMvvV2Efw","colab_type":"code","colab":{}},"cell_type":"code","source":["# weather = pd.read_csv(\"/content/drive/My Drive/xylosai/flightDelay/WeatherDataset.csv\",header=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-AK9qFjagwdk","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","delays = pd.read_csv(\"/content/drive/My Drive/xylosai/flightDelay/FlightDelaysData.csv\",header=0)\n","weather = pd.read_csv(\"/content/drive/My Drive/xylosai/flightDelay/WeatherDataset.csv\",header=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ya2o1j3OLxcJ","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NvDw_dPQCGUk","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"smDDb9NPLxcQ","colab_type":"text"},"cell_type":"markdown","source":["# 2 Cleaning weather data\n","\n","## 2.1 Exploring the weather data\n","\n","Pandas provides some native exploration methods that can be called on a dataframe. we will use describe() and plot(). \n","\n"," 1. [describe()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) provides basic statistics for every column. The output is another dataframe.\n"," 2. [plot()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) is used to plot column data. By default it creates a line plot, but different plots are possible (see docs). It only plots numerical data. For visualizing categorical data, we will use value_counts() on a column first (see below)."]},{"metadata":{"id":"VkSs9nBaLxcM","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"o5B8HULXWJM_","colab_type":"text"},"cell_type":"markdown","source":["Display a list of all columns with their dtypes."]},{"metadata":{"id":"00_whJitWEHM","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5YX3-Mi-OmQW","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.describe()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"81vDNaShkZzj","colab_type":"text"},"cell_type":"markdown","source":["From the table above, we conclude that all the data is from the **Year** 2013. There are **406 516 records** in total. (you can also check this with *len(weather)*)"]},{"metadata":{"id":"3cu5uQuyLxcR","colab_type":"text"},"cell_type":"markdown","source":["## 2.1 Dropping columns with lots of empty strings"]},{"metadata":{"id":"TfHd-fF5gaiP","colab_type":"text"},"cell_type":"markdown","source":["Print the unique values of  **ValueForWindCharacter**. Notice the empty string."]},{"metadata":{"id":"nD9KsI0cLxcR","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"ValueForWindCharacter\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n8-W0Ubzhd_9","colab_type":"text"},"cell_type":"markdown","source":["How many (as a percentage) of the ValueForWindCharacter values are empty strings?"]},{"metadata":{"id":"_syaH9OkLxcV","colab_type":"code","colab":{}},"cell_type":"code","source":["perc = float(weather[weather[\"ValueForWindCharacter\"] == ' '][\"ValueForWindCharacter\"].count())/len(weather)\n","print(perc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NVaQG9Gbhlp1","colab_type":"text"},"cell_type":"markdown","source":["Let's do the same for **PressureTendency, WeatherType, PressureChange** and **HourlyPrecip**"]},{"metadata":{"id":"-7zHVoGGLxcY","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"PressureTendency\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lHIRW4zYLxca","colab_type":"code","colab":{}},"cell_type":"code","source":["perc = float(weather[weather[\"PressureTendency\"] == ' '][\"PressureTendency\"].count())/len(weather)\n","print(perc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2ESGdEoiLxce","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"WeatherType\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mY8qPxJpLxcg","colab_type":"code","colab":{}},"cell_type":"code","source":["perc = float(weather[weather[\"WeatherType\"] == ' '][\"WeatherType\"].count())/len(weather)\n","print(perc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j01iXwNjLxci","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"PressureChange\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6oKMXxTKLxcm","colab_type":"code","colab":{}},"cell_type":"code","source":["perc = float(weather[weather[\"PressureChange\"] == ' '][\"PressureChange\"].count())/len(weather)\n","print(perc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t291nK8PLxcq","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"HourlyPrecip\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VE797_40Lxct","colab_type":"code","colab":{}},"cell_type":"code","source":["perc = float(weather[weather[\"HourlyPrecip\"] == ' '][\"HourlyPrecip\"].count())/len(weather)\n","print(perc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RrcW8sOVLxcv","colab_type":"text"},"cell_type":"markdown","source":["All the columns identified above, contain mostly empty strings. We will drop these columns."]},{"metadata":{"id":"EUK2MXHhLxcv","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.drop(columns=[\"ValueForWindCharacter\",\"PressureTendency\",\"WeatherType\",\"PressureChange\",\"HourlyPrecip\"],inplace=True)\n","weather.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PoBbAJDOLxcx","colab_type":"text"},"cell_type":"markdown","source":["## 2.2 Exploring some other columns and converting to one-hot"]},{"metadata":{"id":"KnH_toobW-Ur","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","**Airport ID** is a categorical value. How many different Airports are in the dataset? How will we deal with categorical values later?"]},{"metadata":{"id":"kMApDJsPXJVR","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"unique airports: \",weather[\"AirportID\"].unique().shape[0])\n","weather[\"AirportID\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CwOYzij2Lxcy","colab_type":"text"},"cell_type":"markdown","source":["We will not one-hot-encode airportID yet, we will first need it later to join the weather data with the flight data."]},{"metadata":{"id":"8FfNcfxJX4FT","colab_type":"text"},"cell_type":"markdown","source":["How many unique values does the **Skycondition** column have? Is it categorical or numerical?\n","\n"]},{"metadata":{"id":"oKbUOAGsLxc1","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"unique SkyCondition: \",weather[\"SkyCondition\"].unique().shape[0])\n","weather[\"SkyCondition\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W_GKSGUjmM1G","colab_type":"text"},"cell_type":"markdown","source":["It contains condition codes that we don't understand.  Since there are so many different values, one-hot-encoding would be impractical. We will drop this column."]},{"metadata":{"id":"Nf0-zKXpmIyv","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.drop(columns=[\"SkyCondition\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"P5h2Cex0m0n2","colab_type":"text"},"cell_type":"markdown","source":["**RecordType** has only four unique values, but their meaning is unknown. We will assume they are not very meaningful and we will drop this column."]},{"metadata":{"id":"QJis8nF7msLT","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"RecordType\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"579Y8oaMmt6o","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.drop(columns=[\"RecordType\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UOEmKk8HnWqa","colab_type":"text"},"cell_type":"markdown","source":[" **Intermediate result**"]},{"metadata":{"id":"CkIr2G_WnVdo","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qYyYIshqncbn","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O1SjVvHeLxdH","colab_type":"text"},"cell_type":"markdown","source":["## 2.3 Removing the M's and casting to numerical. One-hot-encoding WindDirection\n","\n","A lot of numerical values are parsed as an object (see dtypes list above) because they contain some weird \"M\" values.\n","Let's count the M in some of these columns"]},{"metadata":{"id":"eG5IAkfaZn6T","colab_type":"text"},"cell_type":"markdown","source":["From printing the dtypes, **Visibility** is an 'object' type. This suggests that it contains string values. Let's explore this column."]},{"metadata":{"id":"RWNrZ_Izbuix","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"Visibility\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"40XUq9fmcgDa","colab_type":"text"},"cell_type":"markdown","source":["Note the following 'unique' values:\n","\n","-  '10.00' (string)\n","- 10.0 (float)\n","- ' 10.00' (string, but with leading white space)\n","\n","Most values are numerical, but it also contains the 'M' value. Since plot() only takes numerical data, we will make a bar chart of this data by first calling value_counts() on the Series. This returns a Dataframe with the number of matching values for each unique visibility value. Optionally, try calling value_counts() without plot() to see what it does.\n","\n"]},{"metadata":{"id":"khT4sN4jT-TU","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"Visibility\"].value_counts().plot(kind='bar',figsize=(10,10))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0V7xlHaKobkj","colab_type":"text"},"cell_type":"markdown","source":["Most values of visibility are 10.0, the 'M' value rarely appears.\n","\n","We also notice the 'M' value in other columns. Let's zoom in to 3 more columns as an example: **DryBulbFarenheit, Altimeter, SealevelPressure**. Let's calculate the percentage of M's in these columns."]},{"metadata":{"id":"wytudSAz5QD5","colab_type":"code","colab":{}},"cell_type":"code","source":["for column in [\"Visibility\",\"DryBulbFarenheit\", \"Altimeter\", \"SeaLevelPressure\"]:\n","  perc = float(weather[weather[column] == 'M'][column].count())/len(weather)\n","  print(\"Fraction of M's in column {0}: {1}\".format(column,perc))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3tt55SHV6NLf","colab_type":"text"},"cell_type":"markdown","source":["We will remove the column SeaLevelPressure since it contains a lot of useless M's. "]},{"metadata":{"id":"Wg7mOEzq73Eh","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.drop(columns=[\"SeaLevelPressure\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wgXH4gnV79H7","colab_type":"text"},"cell_type":"markdown","source":["In the other columns, the M value is rarely seen. We would prefer to keep these columns, since we are not sure a priori that these columns have no influence on the flight delay.\n","\n","We decide to further clean our data by keeping the columns but simply removing all rows from the dataframe that has an M somewhere.\n","\n","The function below removes all rows with an M for a general dataframe, from all columns with dtype *object*. Afterwards it attempts to cast the column to float.\n"]},{"metadata":{"id":"h2wyLFtG855B","colab_type":"code","colab":{}},"cell_type":"code","source":["def remove_M(df):\n","    original_length = len(df)\n","    for c in df.columns.tolist():\n","        if df.dtypes[c] == 'object':\n","            m = df[df[c] == \"M\"][c].count()\n","            print(\"Removed {0} in column {1}\".format(m,c))\n","            df = df[df[c] != \"M\"]\n","            try: \n","                df[c] = df[c].astype(np.float64)\n","            except:\n","                pass\n","    n_removed = original_length - len(df)\n","    print(\"\")\n","    print(\"Removed {0} of {1}\".format(n_removed,original_length))\n","    return df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y_11JxvHLxdQ","colab_type":"code","colab":{}},"cell_type":"code","source":["weather = remove_M(weather)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6i03sQpm_BGq","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f0wUfB7JLxdW","colab_type":"text"},"cell_type":"markdown","source":["Apparently,  columns **WindSpeed** and **WindDirection** still have weird strings as value, since we were not able to cast them to floats. "]},{"metadata":{"id":"m70QdkPvLxdW","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"unique WindSpeed: \",weather[\"WindSpeed\"].unique().shape[0])\n","weather[\"WindSpeed\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sVFbdAhkERTQ","colab_type":"text"},"cell_type":"markdown","source":["Windspeed has empty strings as value, but only very few. We simply remove the rows with an empty WindSpeed from the dataframe, then we can cast the column to numerical."]},{"metadata":{"id":"QIZIbKGCLxdY","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[weather[\"WindSpeed\"] == '  '][\"WindSpeed\"].count()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VrrZDMsrLxdh","colab_type":"code","colab":{}},"cell_type":"code","source":["weather = weather[weather[\"WindSpeed\"] != '  ']\n","weather[\"WindSpeed\"] = weather[\"WindSpeed\"].astype(np.int64)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KfRncCziLxdg","colab_type":"text"},"cell_type":"markdown","source":["**Winddirection** has some value 'VR' that appears an amount of times that is not negligible."]},{"metadata":{"id":"K0fbxD-BEmht","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"unique WindDirection: \",weather[\"WindDirection\"].unique().shape[0])\n","weather[\"WindDirection\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uVTKBunyLxdp","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[weather[\"WindDirection\"] == 'VR '][\"WindSpeed\"].count()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e_WM1qpVFZRt","colab_type":"text"},"cell_type":"markdown","source":["The Winddirection ranges from 0 to 360 degrees. We will use one-hot-encoding for the WindDirection, by splitting it up into categories. Every category represents a range of 40 degrees. Another category is reserved for the 'VR' case.\n","\n","Review the code in the cell below. This cell performs this one-hot-encoding and splits the column into seperate columns for each one-hot-encoded case. "]},{"metadata":{"id":"C47kE7NOLxdr","colab_type":"code","colab":{}},"cell_type":"code","source":["direction_categories = [0,40,80,120,160,200,240,280,320]\n","def check_cat(x,cat):\n","    try: #try-catch block because VR cannot be compared to int.\n","        if int(x)>cat-20 and int(x)<=cat+20:\n","            return 1\n","        else:\n","            return 0\n","    except:\n","        return 0\n","    \n","weather[\"dir_VR\"] = weather[\"WindDirection\"].apply(lambda x: 1 if x == 'VR ' else 0)\n","for cat in direction_categories:\n","    weather[\"dir_{0}\".format(cat)] = weather[\"WindDirection\"].apply(lambda x: check_cat(x,cat))\n","weather.drop(columns=[\"WindDirection\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9wYBUz3UGFvF","colab_type":"text"},"cell_type":"markdown","source":["The resulting dataframe has columns \"dir_0\" up to \"dir_320\""]},{"metadata":{"id":"tQpnoOw2Lxdt","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WV6XLld9Lxdw","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zeE0XWO7Lxd0","colab_type":"text"},"cell_type":"markdown","source":["## 2.4 Handling time\n","\n","We will use the time information to join the weather dataframe with the delay dataframe. For this, we must format the time information for every row into a fixed format in one column.\n","\n","We round time to the nearest hour. Time of weather data is rounded UP and time of flight data will be rounded DOWN, to make sure that weather conditions after the flight departure/arrival are not a deciding factor. We create a **datetime** column with strings in the format \"YYYY-M-D-H\". \n","\n","What about the timezone? The weather data is reported in local time. We will leave this in local time and use this to join it to the delay data, where arrival and departure times are also in local times.\n","\n","In the original dataframe, time of day is written in the HH-mm format:"]},{"metadata":{"id":"Lq5DMnr0JiUH","colab_type":"code","colab":{}},"cell_type":"code","source":["weather['Time'].head(5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wgAcRo2eJSsD","colab_type":"code","colab":{}},"cell_type":"code","source":["# function to round the time of day (in HH-mm format) to the nearest hour.\n","def hhmm_to_h(hhmm, mode):\n","    #mode = 'up' or 'down'\n","    if not (mode == 'up' or mode == 'down'):\n","        raise Exception(\"mode must be up or down\")\n","    if len(str(hhmm)) <= 2:\n","        if mode == 'up':\n","            h = 1\n","        else:\n","            h = 0\n","    else:\n","        h = int(str(hhmm)[:-2])\n","        if mode == 'up':\n","            h += 1\n","    return h"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E2BynlCBLxeC","colab_type":"code","colab":{}},"cell_type":"code","source":["#first create a column \"hour\" to round the time to the nearest hour.\n","\n","weather[\"hour\"] = weather[\"Time\"].apply(lambda x: hhmm_to_h(x,mode='up'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1hsb0qFRKHt0","colab_type":"code","colab":{}},"cell_type":"code","source":["weather['hour'].head(5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AefUfxRuLxeF","colab_type":"code","colab":{}},"cell_type":"code","source":["#then, create a datetime string from the columns Year, Month, Day and hour. Note how operations on series can be easily done thanks to broadcasting.\n","\n","weather[\"datetime\"] = weather[\"Year\"].astype(str)+'-'+weather[\"Month\"].astype(str)+'-'+weather[\"Day\"].astype(str)+'-'+weather[\"hour\"].astype(str)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ay-Y5E0bKQ0d","colab_type":"code","colab":{}},"cell_type":"code","source":["weather['datetime'].head(5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nizFQ2FBKbby","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eRrWVMh_g4lM","colab_type":"text"},"cell_type":"markdown","source":["## 2.5 Result\n","\n","Dropping some columns that we no longer need."]},{"metadata":{"id":"eOeVoDBrg3wD","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.drop(columns=[\"Year\",\"Month\",\"Day\",\"Time\",\"TimeZone\",\"hour\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vd8y0gRZKbAr","colab_type":"text"},"cell_type":"markdown","source":["The temperature information is redundant: it has both the farenheit and celcius values. We will drop the Farenheit columns. We also drop the Altimeter column."]},{"metadata":{"id":"Lk5V4P8iKoAa","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.drop(columns=[\"DryBulbFarenheit\",\"WetBulbFarenheit\",\"DewPointFarenheit\",\"Altimeter\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nlGR0-OJLxeM","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F8CiQt3hC92c","colab_type":"text"},"cell_type":"markdown","source":["## 2.6 memory usage and dtypes\n","\n","When working with small amounts of data, Pandas works without any problems. For larger datasets, memory usage of the Pandas dataframes becomes to high and the runtime could possible crash. Therefore, we will try to optimize memory usage. If we don't, this notebook will crash when running in the Colaboratory environment. \n","\n","In order to minimize the memory footprint, we have to look at the dtypes of the columns."]},{"metadata":{"id":"ac9eVOfzFIHK","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"abDvIdVXFSWq","colab_type":"text"},"cell_type":"markdown","source":["Pandas uses Numpy arrays internally. Columns of the same dtype are internally stored together in one Numpy Array. \n","\n","The choice of dtype determines the memory usage of the column. A more detailed discussion about memory usage in Pandas is found in this [blog](https://www.dataquest.io/blog/pandas-big-data/), but the ongoing disucssion will make sense without reading the blog.\n","\n","We can inspect a dataframes memory usage as follows:"]},{"metadata":{"id":"qbw3pHXwFQXP","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.info(memory_usage='deep',max_cols=1) #without memory_usage = 'deep', the displayed memory usage is a less accurate approximation."],"execution_count":0,"outputs":[]},{"metadata":{"id":"nceFdUpEK995","colab_type":"text"},"cell_type":"markdown","source":["**currently, our memory usage of the weather dataframe is about 80MB**"]},{"metadata":{"id":"abEqdXhZGdC0","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HBKhPhigKNcw","colab_type":"text"},"cell_type":"markdown","source":["Observe the possible values for the following columns..."]},{"metadata":{"id":"ewxlV5_RIOHF","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"WindSpeed\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8kNglECNLOgX","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"RelativeHumidity\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JF-xw9aFL_lW","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[\"Visibility\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L-otRfp1S6ye","colab_type":"code","colab":{}},"cell_type":"code","source":["#weather[\"Altimeter\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ki5J305KLUQz","colab_type":"code","colab":{}},"cell_type":"code","source":["weather[[\"StationPressure\",\"Visibility\",\"DryBulbCelsius\",\"WetBulbCelsius\",\"DewPointCelsius\",\"RelativeHumidity\"]].head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rKfW9i53OUFf","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"minimum and maximum column values\")\n","for columname in [\"Visibility\",\"StationPressure\"]:\n","  print(\"{0}: minimum = {1}, maximum = {2}\".format(columname,weather[columname].min(),weather[columname].max()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G3Q_MPDFGWJT","colab_type":"text"},"cell_type":"markdown","source":["The interger type has subtypes int8, int 16, int32 and int64. These subtypes have a different memory footprint. An int8 is stored in one byte (8 bits), so it can take 2^8=256 values in total. Thus, it can represent numbers between -128 and 127 (including 0). An int64 is stored in 8 bytes and can take much larger values.\n","\n","**(1) integers**\n","\n","Currently, all our integer columns are int64. We can reduce our memory usage a lot. One of our integer columns, windspeed, ranges from 0 to 64. There is clearly no need for an int64, an int8 would be sufficient. Even the one-hot encoded columns are int64, while they only take the values 0 and 1. \n","\n","A handy way to check the minimal and maximum values of a dtype is np.iinfo() or np.finfo().\n","\n","\n","\n","\n"]},{"metadata":{"id":"Q-iRkw75KMD1","colab_type":"code","colab":{}},"cell_type":"code","source":["print(np.iinfo(np.int64))\n","print(np.iinfo(np.int8))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MDDlbJbvP22j","colab_type":"text"},"cell_type":"markdown","source":["We will **downcast** the one-hot columns and the windspeed to **int8** in the cell below with [pd.to_numeric()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_numeric.html). As an exercise, one might investigate wether an int64 is required for AirportID and optionally downcast it.\n","\n","The to_numeric() method with the 'downcast' parameter will automatically pick the best possible dtype."]},{"metadata":{"id":"BfcZ09RBM1Q3","colab_type":"code","colab":{}},"cell_type":"code","source":["for columnname in [\"WindSpeed\",\"dir_0\",\"dir_40\",\"dir_80\",\"dir_120\",\"dir_160\",\"dir_200\",\"dir_240\",\"dir_280\",\"dir_320\"]:\n","  weather[columnname] = pd.to_numeric(weather[columnname],downcast=\"integer\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M37Lgfz3MgEl","colab_type":"text"},"cell_type":"markdown","source":["**(2) floats**\n","\n","The \"float\" type has subtypes float16, float32, float64 and float128. Currently, all floats are of dtype float64.\n","\n","It is clear that the RelativeHumidity column has simple integer values disguised as floats. The decimal is always zero. We will downcast this to int8. \n","\n","\n"]},{"metadata":{"id":"7iNPUF3fSdGp","colab_type":"code","colab":{}},"cell_type":"code","source":["# weather[\"RelativeHumididty\"] = pd.to_numeric(weather[\"RelativeHumidity\"], downcast=\"float\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DHCvXS7GSdVh","colab_type":"text"},"cell_type":"markdown","source":["The RelativeHumidity, Visiblity, StationPressure and Altimeter columns are floats with decimals, but there minimum and maximum values don't require a float64 - by far. Let's see the minimum and maximum values for some float types."]},{"metadata":{"id":"N8MHLGhcMkKS","colab_type":"code","colab":{}},"cell_type":"code","source":["print(np.finfo(np.float64))\n","print(np.finfo(np.float32))\n","print(np.finfo(np.float16))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0ZECV_i9PXaM","colab_type":"text"},"cell_type":"markdown","source":["Looks like a smaller float will do. Downcast!"]},{"metadata":{"id":"STD_FaBIPbbt","colab_type":"code","colab":{}},"cell_type":"code","source":["for columnname in [\"StationPressure\",\"Visibility\",\"DryBulbCelsius\",\"WetBulbCelsius\",\"DewPointCelsius\",\"RelativeHumidity\"]:\n","  weather[columnname] = pd.to_numeric(weather[columnname],downcast=\"float\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3kkH2w4qUY21","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.info(memory_usage=\"deep\",max_cols=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fZ9hCgmTe6R6","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bDdM9WHXLxeO","colab_type":"text"},"cell_type":"markdown","source":["# 3 Cleaning delay data\n","\n"]},{"metadata":{"id":"_Et5EY_Jgnht","colab_type":"text"},"cell_type":"markdown","source":["## 3.1 Dropping and one-hot-encoding"]},{"metadata":{"id":"jno0DgpgLxeP","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ap3YNIq1MbFo","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CVEiSFj8M3M2","colab_type":"text"},"cell_type":"markdown","source":["**DayOfWeek** has values ranging from 0 (Monday) to 6 (Sunday). We will not need this column so we drop it."]},{"metadata":{"id":"_rCvWNyKMmBD","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"unique DayOfWeek: \",delays[\"DayOfWeek\"].unique().shape[0])\n","delays[\"DayOfWeek\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UEj0DfYRNASz","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.drop(columns = \"DayOfWeek\",inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O6bG2ZurNEzm","colab_type":"text"},"cell_type":"markdown","source":["**Carrier** is a categorical value with 16 categories. "]},{"metadata":{"id":"7e1tEdIuLxeR","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"unique Carrier: \",delays[\"Carrier\"].unique().shape[0])\n","delays[\"Carrier\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1j04RwPDN2Io","colab_type":"text"},"cell_type":"markdown","source":["We will one-hot encode this column. Below is a function to perform this one-hot-encoding. Notice the important memory optimization! Later we will use this function to one-hot encode the airportID's which creates over hundred new columns. You are not able to run this one-hot-encoding without the memory optimization line."]},{"metadata":{"id":"Itp6Oi3zLxeU","colab_type":"code","colab":{}},"cell_type":"code","source":["def one_hot(df,features):\n","    all_column_names = []\n","    for feature in features:\n","        names = list(df[feature].unique())\n","        for i, name in enumerate(names):\n","            column_name = str(feature)+'_'+str(i)\n","            df[column_name] = df[feature].apply(lambda x: 1 if x==name else 0)\n","            df[column_name] = pd.to_numeric(df[column_name],downcast='integer') #memory optimization!!\n","            all_column_names.append(column_name)\n","    df.drop(columns=features)\n","    return df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dvTdqhCCLxeZ","colab_type":"code","colab":{}},"cell_type":"code","source":["delays = one_hot(delays,[\"Carrier\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9TU-YR_XghwT","colab_type":"text"},"cell_type":"markdown","source":["## 3.2 Handling time"]},{"metadata":{"id":"poW137E_OJck","colab_type":"text"},"cell_type":"markdown","source":["Departure and arrival times: we round **CRSDepTime** and **CRSArrTime** to the nearest hour, creating the columns **Dep_hour** and **Arr_hour**. We round *down*, while the hour of the weather was rounded *up*.  This is to make sure that weather conditions after the flight departure/arrival are not a deciding factor."]},{"metadata":{"id":"1VjWHjMwLxeW","colab_type":"code","colab":{}},"cell_type":"code","source":["delays[\"Dep_hour\"] = delays[\"CRSDepTime\"].apply(lambda x: hhmm_to_h(x,mode=\"down\"))\n","delays[\"Arr_hour\"] = delays[\"CRSArrTime\"].apply(lambda x: hhmm_to_h(x,mode=\"down\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5s20WC8DLxeb","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XR23N67TLxed","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.columns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yvZ68YbJLxee","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7jUAiH3ALxeg","colab_type":"text"},"cell_type":"markdown","source":["We will create columns **Dep_datetime** and **Arr_datetime** in the same format as the **Datetime** column in the weather dataset. We will use these columns later to join the delay data with the weather data.\n","\n","By inspecting the columns above, we can see that the flight info has only one 'DayofMonth'. We assume this is the day of *departure*. However, when a flight takes place overnight, the arrival might be on the next day. This must be taken into account when constructing the Dep_datetime and Arr_datetime columns.\n","\n","We assume the departure and arrival hour (Dep_hour and Arr_hour) are in the local timezone of the departure and arrival airports respectively. If departure time is later than arrival time, then the arrival is on the next day, so this must be taken into account when constructing Arr_datetime and Dep_datetime (add one day to Dep_datetime). \n","\n","We introduce the helper column **dep_after_arr** (1 or 0). This column is '1' if the arrival date in on the next day and '0' otherwise.\n","\n"]},{"metadata":{"id":"UD-n6BtJLxeh","colab_type":"code","colab":{}},"cell_type":"code","source":["delays[\"dep_after_arr\"] = (delays[\"CRSArrTime\"]<delays[\"CRSDepTime\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6Nc2BcH2Lxei","colab_type":"code","colab":{}},"cell_type":"code","source":["delays[\"Dep_datetime\"] = delays[\"Year\"].astype(str)+'-'+delays[\"Month\"].astype(str)+'-'+delays[\"DayofMonth\"].astype(str)+'-'+delays[\"Dep_hour\"].astype(str)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kjvhom0yT4i1","colab_type":"text"},"cell_type":"markdown","source":["We add an extra helper column **DayofMonth_arr**, the day of month of *arrival*. This is one day later than the **DayofMonth** column if arrival is one day later (i.e, when dep_after_arr is 1) and the same as **DayofMonth** otherwise."]},{"metadata":{"id":"-AJqi48HLxek","colab_type":"code","colab":{}},"cell_type":"code","source":["delays[\"DayofMonth_arr\"] = delays[\"DayofMonth\"]+delays[\"dep_after_arr\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"caDXB-iVUUqB","colab_type":"text"},"cell_type":"markdown","source":["From this, we can create **Arr_datetime**"]},{"metadata":{"id":"xxK1bkvJLxeo","colab_type":"code","colab":{}},"cell_type":"code","source":["delays[\"Arr_datetime\"] = delays[\"Year\"].astype(str)+'-'+delays[\"Month\"].astype(str)+'-'+delays[\"DayofMonth_arr\"].astype(str)+'-'+delays[\"Arr_hour\"].astype(str)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4kkhl6tgVpSq","colab_type":"text"},"cell_type":"markdown","source":["## 3.3 Result\n","\n","Let's drop some columns we no longer need."]},{"metadata":{"id":"Cqj_oOm_VWPL","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.drop(columns=[\"dep_after_arr\",\"DayofMonth\",\"DayofMonth_arr\",\"CRSArrTime\", \"CRSDepTime\",\"Dep_hour\",\"Arr_hour\",\"Year\",\"Month\",\"Carrier\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kA_HWRTDgICZ","colab_type":"text"},"cell_type":"markdown","source":["The result is as follows.."]},{"metadata":{"id":"vZf_dUoFgUin","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4IIekvCxgWqG","colab_type":"text"},"cell_type":"markdown","source":["## 3.4 memory usage and dtypes\n","\n"]},{"metadata":{"id":"0eqQbgPgiybI","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.info(memory_usage='deep')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dibm7edBLxer","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"blAkq_gEjIsH","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fKgUz5iEjMME","colab_type":"text"},"cell_type":"markdown","source":["DepDelay and ArrDelay are now floats but they can be casted to integers. ArrDelay15 and Cancelled are floats that are actually binary 1 or 0. The one-hot encoded features are int64, while an int8 should be sufficient. \n","\n","We will downcast all values as integers, except for the datetime columns."]},{"metadata":{"id":"6zc14Z6IjKjk","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.columns[0:-2]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WvUAhHJlhOTZ","colab_type":"code","colab":{}},"cell_type":"code","source":["for columnname in delays.columns[0:-2]: #excluse the last two (datetimes Dep_datetime and Arr_datetime objects)\n","  delays[columnname] = pd.to_numeric(delays[columnname],downcast=\"integer\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kBuOHBhthekQ","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iXtG7va4kCLv","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.info(memory_usage='deep')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a_P2GXX8Lxew","colab_type":"text"},"cell_type":"markdown","source":["# 4 Join with OriginAirport weather"]},{"metadata":{"id":"5eRrNBW2Lxew","colab_type":"text"},"cell_type":"markdown","source":["Apparently, in the weather data sometimes for the same airport two measurements are available in the same hour (i.e. same datetime). We need to drop these duplicates (keeping the last available) so that we have unique airport-datetime combinations. Then, we can index on these columns (double index) and join the dataframes. "]},{"metadata":{"id":"wIe2G2QzLxew","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.drop_duplicates(subset=[\"AirportID\",\"datetime\"],keep=\"last\",inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gnzJb-ljLxe2","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.set_index(keys=[\"AirportID\",\"datetime\"],inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wZyr6ZxUhijz","colab_type":"code","colab":{}},"cell_type":"code","source":["weather.head(5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TSls1_50Lxe5","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xbgBoNFoh-f0","colab_type":"text"},"cell_type":"markdown","source":["We are now ready to add the weather information to our delays dataframe. We will first join with the weather at the departure airport. \n","\n","In order to perform the join, we must temporarily rename our OriginAirportID to AirportID and Dep_datetime to datetime. The column names to be joined on, are then equal in both dataframes of the join."]},{"metadata":{"id":"NSSwD8KjLxe7","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.rename(columns={\"OriginAirportID\":\"AirportID\",\"Dep_datetime\":\"datetime\"},inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6Akug-eii5mw","colab_type":"text"},"cell_type":"markdown","source":["Now, adding the weather of the departure airport to the dataframe..."]},{"metadata":{"id":"mZQCYCeQldRS","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xUZ-pINzLxe9","colab_type":"code","colab":{}},"cell_type":"code","source":["delays=delays.join(weather,on=[\"AirportID\",\"datetime\"])#,rsuffix=\"_depweather\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aUYo0dZ-3Efa","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"mD3t9WXKjZ_L","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.columns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VULDdKVnk44n","colab_type":"text"},"cell_type":"markdown","source":["A lot of columns have been added related to the weather at the origin airport. We will rename all these columns with a suffix **_originairport** so that we can distinct them later from the weather data of the destination airport. We also change  AirportID back to OriginAirportID and datetime to Dep_datetime"]},{"metadata":{"id":"WkpXwiyiLxfE","colab_type":"code","colab":{}},"cell_type":"code","source":["delays_columns_old = delays.columns\n","delays_columns_new = []\n","for column in delays_columns_old:\n","    if column in weather.columns:\n","        delays_columns_new.append(column+\"_originAirport\")\n","    else:\n","        delays_columns_new.append(column)\n","        \n","delays.columns = delays_columns_new\n","delays.rename(columns={\"AirportID\":\"OriginAirportID\",\"datetime\":\"Dep_datetime\"},inplace=True)\n","delays.columns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JvPoSvo6LxfH","colab_type":"text"},"cell_type":"markdown","source":["# 5 Join with DestinationAirport weather"]},{"metadata":{"id":"KoZ6iFgen8ky","colab_type":"text"},"cell_type":"markdown","source":["We now perform the same tricks with the destination airport weather."]},{"metadata":{"id":"fHXoxRQvLxfI","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.rename(columns={\"DestAirportID\":\"AirportID\",\"Arr_datetime\":\"datetime\"},inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"saM5xOmeLxfL","colab_type":"code","colab":{}},"cell_type":"code","source":["delays=delays.join(weather,on=[\"AirportID\",\"datetime\"])#,rsuffix=\"_arrweather\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"o4LzDYo2LxfL","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.columns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nKciqITBLxfR","colab_type":"code","colab":{}},"cell_type":"code","source":["delays_columns_old = delays.columns\n","delays_columns_new = []\n","for column in delays_columns_old:\n","    if column in weather.columns:\n","        delays_columns_new.append(column+\"_destAirport\")\n","    else:\n","        delays_columns_new.append(column)\n","        \n","delays.columns = delays_columns_new\n","delays.rename(columns={\"AirportID\":\"DestAirportID\",\"datetime\":\"Arr_datetime\"},inplace=True)\n","delays.columns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZLqqL0dOLxfS","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vRO5an8RplMk","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G09Aoiuypl9a","colab_type":"text"},"cell_type":"markdown","source":["# 6 Final data processing and result"]},{"metadata":{"id":"q9uzbssgLxfU","colab_type":"text"},"cell_type":"markdown","source":["Finally, we drop some unneeded columns. Let's assume that the exact flight times don't matter, only the weather conditions at those times. For now the only target variable is ArrDelay15, we exclude other related columns."]},{"metadata":{"id":"l6OWlW83LxfU","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.drop(columns=[\"Dep_datetime\",\"Arr_datetime\",\"DepDelay\",\"DepDel15\",\"ArrDelay\",\"Cancelled\"],inplace=True)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dH7Z8-Thp36A","colab_type":"text"},"cell_type":"markdown","source":["Dropping NaN values"]},{"metadata":{"id":"qxn5uG0cLxfW","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dropna(inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UY2ARDMtsAX3","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L9A1LR8OrpgO","colab_type":"text"},"cell_type":"markdown","source":["During the join, our columns related to Windspeed and Wind Direction are now back to float64. Cast them back to integers to conserve memory"]},{"metadata":{"id":"nvuJy6CktREX","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.info(memory_usage='deep',max_cols=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CPt5uh6Prv2H","colab_type":"code","colab":{}},"cell_type":"code","source":["def isDowncastColumn(columnName):\n","    if (\"dir_\" in columnName) or (\"WindSpeed\" in columnName):\n","      return True\n","    else:\n","      return False\n","    \n","for columnName in filter(isDowncastColumn,list(delays.columns)):\n","  delays[columnName] = pd.to_numeric(delays[columnName],downcast='integer')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zyOXpee1q3QZ","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.dtypes"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ok5tuoaZq3Hg","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.info(memory_usage='deep',max_cols=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NGKB7-q2rno4","colab_type":"text"},"cell_type":"markdown","source":["Now, we must one-hot-encode the destination and origin airport ID's. Since there are 64 options for each, this will introduce 128 new one-hot features!"]},{"metadata":{"id":"SJsnAXOHsWCO","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"unique origin airports: {0}\".format(delays[\"OriginAirportID\"].unique().shape[0]))\n","print(\"unique destination airports: {0}\".format(delays[\"DestAirportID\"].unique().shape[0]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"POxHBRfHrskS","colab_type":"code","colab":{}},"cell_type":"code","source":["#this might take a few minutes...\n","delays = one_hot(delays,[\"OriginAirportID\",\"DestAirportID\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FzztioTowpyM","colab_type":"text"},"cell_type":"markdown","source":["Our resulting dataset has 61 columns (60 feature columns and one target output). Our data preprocessing was limited to one-hot-encoding, cleaning the data, and doing some manipulations on the time information. No advanced feature engineering was done."]},{"metadata":{"id":"_GdLhu39vRVH","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head(5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r-RXZZZIvTru","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.info(memory_usage='deep')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wCniCAagvYW9","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.columns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D53uAMO6v1wo","colab_type":"text"},"cell_type":"markdown","source":["Our target variable is **ArrDel15**, a binary (0 or 1) indicating wether or not the flight arrives at least 15 minutes late."]},{"metadata":{"id":"9h3HkA_PwDER","colab_type":"code","colab":{}},"cell_type":"code","source":["delays[\"ArrDel15\"].head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gQZWKHosdBuS","colab_type":"code","colab":{}},"cell_type":"code","source":["# saving the dataframe to a CSV file. We will use it later.\n","\n","delays.to_csv(\"/content/drive/My Drive/xylosai/flightDelay/FlightDelaysData_clean.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gspykWhRwWzM","colab_type":"text"},"cell_type":"markdown","source":["# 7 Logistic regression"]},{"metadata":{"id":"XO3wgfjQxQIU","colab_type":"text"},"cell_type":"markdown","source":["## 7.1 Introduction\n","\n","In this notebook we will build a binary classifier using logistic regression. Our goal is to build a model that is able to determine wether or not a commercial aircraft flight will be delayed or not, based on information such as the weather conditions and the carrier of the flight.\n","\n","In logistic regression for binary classification, there are only 2 classes: 1 and 0. An output Z is calculated as a linear function of the features. The result of this is \"activated\" with a softmax activation function, causing the resulting output to fall in the interval ]0,1[, interpreted as a probability P(Y'=1). Then, at prediction time, we will predict \"1\" if the output is above some threshold (usually 0.5).\n","\n","$Z = w_0 + w_1h_1 + w_2h_2 + ... + w_nh_n$\n","\n","$Y' =  sigmoid(Z) = 1/(1+exp(-Z)$\n","\n","\n","Logistic regression is a **linear classifier**. It can only find a linear decision boundary in the features $h_i$. In general, features are any function of the \"raw\" inputs $x_i$. This allows to learn a non-linear relationship between output and input. In our case, the features are all the columns in the dataset (except for the target column).\n","\n","\n","\n"]},{"metadata":{"id":"z75OjcQ-arcm","colab_type":"text"},"cell_type":"markdown","source":["## 7.2 The implications of linearity\n","\n","The implications of linearity can be explained better with the **WindDirection** input. It is reasonable to assume that the wind direction has an influence on flight delays. Maybe, if the wind direction is perpendicular to the direction of take-off, take-off might be impeded. \n","\n","The possible values for the wind direction range from 0° to 360° plus some 'VR' case. Going back to our formula, if one of the features was the winddirection, a weight must be learned that encodes the influence of wind direction. \n","\n","Learning a positive weight would mean that a \"high\" degree (closer to 360°) causes flight delay. Then, $Z$ will be higher so that the output $Y'$ is close to one, leading to a prediction of 1 (1 = delay, 0 = no delay). \n","\n","Generally, there is no reason to believe that a \"high\" degree (close to 360°) is better for take-off then a \"low degree\" (close to 0°). With feature engineering, we could find a non-linear relationship with wind direction, but then we still have no way to deal with the 'VR' case.\n","\n","But we have one-hot-encoded our wind direction in ranges of 40°. Each of these one-hot-encoded features has its own weight. If the wind direction is 165°, only the weight of the one-hot-encoded feature **dir_160** will influence the outcome, since all other one-hot-encoded features are zero. This way, the model can learn that, for example, a wind direction of 160° causes delay (a high weight) and wind directions close to 0° or close to 360° are less likely to cause delay (a low weight).\n","\n","This could work if there was only airport in the dataset. But our model - and its weights - applies to all airports in the dataset. Different airports have a different orientation. A wind direction of 165° degree might be beneficial for one airport, but not for the other. Therefore, it is unlikely to assume that weights can be learned that work for all airports. In order to truly take into account the wind direction, some single feature $h_i$ should be engineered that is a function of both airportID and wind direction simultaneously. It is unclear how this feature should look. **It looks like taking into account wind direction is not easily done with a linear classifier like logistic regression...**. For logistic regression, we will drop features related to wind direction (**dir_0** to **dir_320**.)\n","\n","We will later see that the problem of manual feature engineering is addressed with neural networks. Neural networks are able to find non-linear relationships between input and output, without feature engineering. With neural networks, wind direction would not even have to be one-hot-encoded if consisted of only numerical value and it did not contain the weird 'VR' value. Unfortunately, because of this 'VR' value, we will keep the one-hot-encoded wind direction features even for the neural network example later.\n","\n"]},{"metadata":{"id":"_yYWouU-769X","colab_type":"text"},"cell_type":"markdown","source":["## 7.3 Building a first model\n","\n","Drop columns related to wind direction."]},{"metadata":{"id":"_-6nGLkH8rAR","colab_type":"code","colab":{}},"cell_type":"code","source":["#might be needed to conserve memory\n","del weather"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ymfHaIJe-xIK","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wq-G7MNHwWHw","colab_type":"code","colab":{}},"cell_type":"code","source":["def isDirectionColumn(columnName):\n","    if \"dir_\" in columnName:\n","      return True\n","    else:\n","      return False\n","    \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EhlK4ChfwWES","colab_type":"code","colab":{}},"cell_type":"code","source":["directionColumns = filter(isDirectionColumn,list(delays.columns))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U1qKX4hTwWAV","colab_type":"code","colab":{}},"cell_type":"code","source":["delays = delays.drop(columns = directionColumns) #note: inplace = False (default)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n8rQ0Mik8l2v","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dV8ixRNN9WMV","colab_type":"code","colab":{}},"cell_type":"code","source":["delays.columns"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vOqniqLn9z-Q","colab_type":"code","colab":{}},"cell_type":"code","source":["Y = delays[\"ArrDel15\"].astype(np.float64)\n","X = delays.drop(columns=[\"ArrDel15\"]).astype(np.float64)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NLtsUe0EBhIR","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=0,test_size = 0.10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QKwthofy_dSV","colab_type":"text"},"cell_type":"markdown","source":["Creating a model. Read the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for logistic regression in sklearn. Are we applying any regularization?"]},{"metadata":{"id":"SG2c1YrZ-h2z","colab_type":"code","colab":{}},"cell_type":"code","source":["model_logreg = LogisticRegression(random_state = 0)\n","model_logreg.fit(X_train,Y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OaHGRIOLBIBw","colab_type":"text"},"cell_type":"markdown","source":["## 7.4 Evaluating the model\n","\n","the score() method returns the accuracy of a model on a dataset. As usual, we evaluate our model on the unseen **test set**"]},{"metadata":{"id":"NN-f8Yj-AT8q","colab_type":"code","colab":{}},"cell_type":"code","source":["accuracy = model_logreg.score(X_test,Y_test)\n","print(\"Accuracy: {0}\".format(accuracy))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dpIrH-pECVbW","colab_type":"code","colab":{}},"cell_type":"code","source":["perc_ontime = float(len(delays[delays[\"ArrDel15\"] == 0]))/len(delays)\n","print(\"fraction of flights that are on time: {0}\".format(perc_ontime))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oT2jqeysCM9G","colab_type":"text"},"cell_type":"markdown","source":["The accuracy of 79% is not a good performance indicator. Since 79% percent of the dataset is not-delayed (ArrDel15 = 0), a majority class classifier would achieve the same accuracy. Maybe the model has simply learned that basically all flights are on time?"]},{"metadata":{"id":"kLhdWHjYDT9C","colab_type":"code","colab":{}},"cell_type":"code","source":["predictions = model_logreg.predict(X_test)\n","pred_positive = np.sum(predictions == 1)\n","pred_negative = np.sum(predictions == 0)\n","print(\"predicted positive: {0}\".format(pred_positive))\n","print(\"predicted negative: {0}\".format(pred_negative))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3IGteMANUWqb","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","We calculate the Area Under the (ROC) Curve (AUC) using Sklearn's builtin functionality ([documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score)). First we must predict the probabilities without applying a threshold with [predict_proba](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba). Predict_proba returns a Numpy array with the probabilities of each class, for each data point. The sum of each row (the sum of both columns in this case of binary classification) is one. "]},{"metadata":{"id":"ofEOycLzUt8A","colab_type":"code","colab":{}},"cell_type":"code","source":["Y_test_prob = model_logreg.predict_proba(X_test)\n","Y_test_prob"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tAyD4n3SXdO-","colab_type":"text"},"cell_type":"markdown","source":["Our function for calculating AUC requires the probability estimates of the positive class, i.e. the second column of Y_test_prob (since columns are ordered by the label of classes, so the first column is class 0 and class 1)."]},{"metadata":{"id":"VFe_gKFMWcqC","colab_type":"code","colab":{}},"cell_type":"code","source":["auc = sklearn.metrics.roc_auc_score(Y_test,Y_test_prob[:,1])\n","print(auc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xUEx4MOFYPBM","colab_type":"text"},"cell_type":"markdown","source":["We can also plot the roc curve of a binary classifier with the [roc_curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) method and matplotlib. A **good classifier has**, for all thresholds, a **high true positive rate** while still maintaining a **low false positive rate**, i.e. a high area under the curve. A worthless random classifier (baseline) has AUC = 0.5 and is drawn as a 45° degree straight line: fpr and tpr are equal for any threshold. Let's plot our ROC curve together with the baseline. We create a function plotROC for this, since we will need to do this again later."]},{"metadata":{"id":"avh4UWGvYOV5","colab_type":"code","colab":{}},"cell_type":"code","source":["fpr, tpr, tresholds = sklearn.metrics.roc_curve(Y_test, Y_test_prob[:,1])\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"TwlH0W34bhKK","colab_type":"code","colab":{}},"cell_type":"code","source":["def plotROC(fpr, tpr):\n","  fig = plt.figure(figsize = (10,10))\n","  plt.xlabel(\"false positive rate (FPR)\",fontsize = 15)\n","  plt.ylabel(\"true positive rate (TPR)\",fontsize = 15)\n","  plt.title(\"ROC curve\",fontsize=20)\n","  plt.plot(fpr, tpr,\"b\",fpr, fpr, \"k:\")\n","  plt.legend((\"ROC curve\",\"baseline\"),fontsize=15)\n","  plt.show()\n","\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"TEFoKPgwZVMG","colab_type":"code","colab":{}},"cell_type":"code","source":["plotROC(fpr, tpr)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OGhJkoAxYxSc","colab_type":"text"},"cell_type":"markdown","source":["## 7.5 Dealing with imbalanced classes (undersampling)\n","\n","In our data, 79% of flights were on time (class 0). Therefore, our model is biased towards predicting 0. We will now balance our training data so that it contains an equal amount of positive (1) and negative (0) samples. With this balanced set we fit a new classifier, and evaluate on the same test set.\n","\n","Note that we balance our training set, but we still evaluate our model on the original test set so that the test"]},{"metadata":{"id":"Mn9jQq9ZE5eH","colab_type":"code","colab":{}},"cell_type":"code","source":["# category count before balancing\n","print(\"not delayed: {0}\".format(np.sum(Y_train == 0)))\n","print(\"delayed: {0}\".format(np.sum(Y_train == 1)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_LlSebM7nh9H","colab_type":"code","colab":{}},"cell_type":"code","source":["# THIS IS THE ORIGINAL CODE FOR BALANCING THE CLASSES. READ AND UNDERSTAND IT FIRST.\n","# THE CELL BELOW PERFORMS THE SAME TASK, BUT IS MORE MEMORY-OPTIMIZED. \n","# (memory is limited to about 12GB in Colaboratory).\n","\n","# #split training data into classes\n","# X_train_1 = X_train[Y_train == 1]  #minority\n","# Y_train_1 = Y_train[Y_train == 1]\n","\n","# X_train_0 = X_train[Y_train == 0]  #majority\n","# Y_train_0 = Y_train[Y_train == 0]\n","\n","# X_train_0 = X_train_0[0:len(Y_train_1)]\n","# Y_train_0 = Y_train_0[0:len(Y_train_1)]\n","\n","# #shapes should be equal\n","# print(X_train_1.shape, X_train_0.shape)\n","# print(Y_train_1.shape, Y_train_0.shape)\n","\n","# X_train_balanced = pd.concat([X_train_1, X_train_0],axis=0)\n","# Y_train_balanced = pd.concat([Y_train_1, Y_train_0],axis=0)\n","\n","# #shuffling first could improve training\n","# X_train_balanced, Y_train_balanced = sklearn.utils.shuffle(X_train_balanced, Y_train_balanced, random_state=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kFZ952ALE7T3","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"LNLTpdqVCrmI","colab_type":"code","colab":{}},"cell_type":"code","source":["# balancing the classes in the train set, memory-optimized\n","\n","l_1 = np.sum(Y_train == 1)\n","\n","\n","X_train = pd.concat([X_train[Y_train == 1], X_train[Y_train == 0][0:l_1]],axis=0)\n","Y_train = pd.concat([Y_train[Y_train == 1], Y_train[Y_train == 0][0:l_1]],axis=0)\n","\n","X_train, Y_train = sklearn.utils.shuffle(X_train, Y_train, random_state=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"joZBudpdsfDI","colab_type":"code","colab":{}},"cell_type":"code","source":["# category count after balancing\n","print(\"not delayed: {0}\".format(np.sum(Y_train == 0)))\n","print(\"delayed: {0}\".format(np.sum(Y_train == 1)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oGrUytRuqk0b","colab_type":"text"},"cell_type":"markdown","source":["Training a new model on balanced training set, and evaluate on the (non-balanced) test set."]},{"metadata":{"id":"eiJ6wK2JqjUm","colab_type":"code","colab":{}},"cell_type":"code","source":["model_logreg = LogisticRegression(random_state = 0)\n","model_logreg.fit(X_train,Y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"48ZQRFrHoiUP","colab_type":"code","colab":{}},"cell_type":"code","source":["Y_test_prob = model_logreg.predict_proba(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g0XOpPFBr_fp","colab_type":"code","colab":{}},"cell_type":"code","source":["auc = sklearn.metrics.roc_auc_score(Y_test,Y_test_prob[:,1])\n","auc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WbrVT89DxAr_","colab_type":"text"},"cell_type":"markdown","source":["With undersampling, our AUC score has improved slightly from 0.61 to 0.66.\n","\n","It is important to mention that for a different random subset of the training data, or a different random test-train split, the results can be slightly different."]},{"metadata":{"id":"fiFDUkdgsARW","colab_type":"code","colab":{}},"cell_type":"code","source":["fpr, tpr, tresholds = sklearn.metrics.roc_curve(Y_test, Y_test_prob[:,1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pQzcnpo_sVCc","colab_type":"code","colab":{}},"cell_type":"code","source":["plotROC(fpr, tpr)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pK8EZe4yLxgE","colab_type":"text"},"cell_type":"markdown","source":["# X Dense neural network (to do)"]},{"metadata":{"id":"o-crdTg_LxgE","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import layers\n","from keras.layers import Input, Add, Dense, Activation, Dropout, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n","from keras.models import Model, load_model\n","from keras.initializers import glorot_uniform\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zVpFDvazLxgF","colab_type":"code","colab":{}},"cell_type":"code","source":["def delayNNmodel(input_shape,hidden_units = [100,100],dropout_rate = 0.1):\n","    \n","    #input layer\n","    X_input = Input(input_shape)\n","    \n","    #first hidden layer\n","    X = Dense(hidden_units[0])(X_input)\n","    X = Activation('relu')(X)\n","    X = Dropout(dropout_rate,seed=0)(X)\n","    \n","    #next hidden layer(s)\n","    if len(hidden_units)>2:\n","        for n in hidden_units[1:]:\n","            X = Dense(n)(X)\n","            X = Activation('relu')(X)\n","            X = Dropout(dropout_rate,seed=0)(X)\n","    elif len(hidden_units) == 2:\n","        X = Dense(hidden_units[1])(X)\n","        X = Activation('relu')(X)\n","        X = Dropout(dropout_rate,seed=0)(X)\n","        \n","    #output layer\n","    X = Dense(1)(X)\n","    X = Activation('sigmoid')(X)\n","    \n","    model = Model(inputs = X_input, outputs = X, name = 'delayBinaryClassifierNN')\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q0_14-xmLxgG","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluate_NN(model,X,Y,plot=False):\n","    Y_pred = model.predict(X)\n","    fpr,tpr,thresholds = roc_curve(Y,Y_pred)\n","    if plot:\n","        plt.plot(fpr,tpr)\n","    AUC = auc(fpr,tpr)\n","    return AUC"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yjJWRktLLxgG","colab_type":"code","colab":{}},"cell_type":"code","source":["def fit_and_plot(model,X_train,Y_train,X_test,Y_test,epochs = 10,verbose=False,evaluate_offset = 0):\n","    auc_test = []\n","    auc_train = []\n","    for i in range(epochs):\n","        print(i)\n","        model.fit(X_train,Y_train,epochs=1,batch_size=128,verbose=0)\n","        if i >= evaluate_offset:\n","            auc_test_ = evaluate_NN(model,X_test,Y_test,plot=False)\n","            auc_test.append(auc_test_)\n","            auc_train_ = evaluate_NN(model,X_train,Y_train,plot=False)\n","            auc_train.append(auc_train_)\n","            if verbose:\n","                print(\"Epoch {2}. Test auc: {0}, Train auc: {1}\".format(auc_test_,auc_train_,i))\n","    plt.figure()\n","    plt.plot(np.arange(len(auc_test)),auc_test,'r',np.arange(len(auc_train)),auc_train,'b')\n","    plt.show()\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ORK2bqVuLxgH","colab_type":"text"},"cell_type":"markdown","source":["**never name the output of this function 'auc' since it collides with the name of the function auc, imported above**"]},{"metadata":{"id":"bjsiRGw4LxgI","colab_type":"text"},"cell_type":"markdown","source":["auc_ = evaluate_NN(model,X_test,Y_test,plot=False)\n","print(auc_)"]},{"metadata":{"id":"kzvCyWX6LxgJ","colab_type":"text"},"cell_type":"markdown","source":["**Output is always 0, see cell below. Let's try to balance to dataset first, since it is skewed towards output 0**"]},{"metadata":{"id":"pOkJjJOvLxgK","colab_type":"code","colab":{}},"cell_type":"code","source":["pred=model.predict(X_train)\n","np.sum(pred>0.00001)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dsTRHcccLxgL","colab_type":"code","colab":{}},"cell_type":"code","source":["np.sum(Y_train==1)/Y_train.shape[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h4bGjURgLxgM","colab_type":"code","colab":{}},"cell_type":"code","source":["np.sum(Y_train==0)/Y_train.shape[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mEA5rl_YLxgN","colab_type":"code","colab":{}},"cell_type":"code","source":["#turn this into a robust reusable function!\n","\n","index_0 = (Y_train==0)\n","index_1 = (Y_train==1)\n","print(np.sum(index_0))\n","print(np.sum(index_1))\n","amt_1 = np.sum(index_1)\n","Y_train_0 = Y_train[index_0]\n","Y_train_1 = Y_train[index_1]\n","X_train_0 = X_train[index_0]\n","X_train_1= X_train[index_1]\n","\n","np.random.seed(0)\n","selection_0 = np.random.randint(0,Y_train_0.shape[0],amt_1)\n","\n","Y_train_0_selected = Y_train_0[selection_0]\n","X_train_0_selected = X_train_0[selection_0]\n","\n","X_train_balanced = np.append(X_train_0_selected,X_train_1,axis=0)\n","Y_train_balanced = np.append(Y_train_0_selected,Y_train_1,axis=0)\n","\n","print(X_train_balanced.shape)\n","print(np.expand_dims(Y_train_balanced,axis=1).shape)\n","\n","XY = np.append(X_train_balanced,np.expand_dims(Y_train_balanced,axis=1),axis=1)\n","np.random.shuffle(XY)\n","X_train_balanced = XY[:,0:-1]\n","Y_train_balanced = XY[:,-1]\n","\n","print(X_train_balanced.shape)\n","print(Y_train_balanced.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5NRDRTrzLxgP","colab_type":"code","colab":{}},"cell_type":"code","source":["input_shape = [X_train.shape[1]]\n","model = delayNNmodel(input_shape,dropout_rate=0)\n","fit_and_plot(model,X_train_balanced,Y_train_balanced,X_test,Y_test,verbose=True,epochs=3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IEHExjXmLxgR","colab_type":"code","colab":{}},"cell_type":"code","source":["auc_ = evaluate_NN(model,X_test,Y_test,plot=False)\n","print(auc_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ACG35-J-LxgR","colab_type":"code","colab":{}},"cell_type":"code","source":["units = [[128,128],[128,128,128],[256,256,128]]\n","dropout_rates = [0,0.05,0.1,0.2]\n","for u in units:\n","    for dropout_rate in dropout_rates:\n","        model = delayNNmodel(input_shape, hidden_units = u, dropout_rate = dropout_rate)\n","        print(\"units: {0}, dropout: {1}\".format(u,dropout_rate))\n","        fit_and_plot(model,X_train_balanced,Y_train_balanced,X_test,Y_test,verbose=False,epochs=6)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vOu_QXLALxgX","colab_type":"text"},"cell_type":"markdown","source":["**doing extra epochs for those who seem promising**"]},{"metadata":{"id":"6ZjGBRJ7LxgX","colab_type":"code","colab":{}},"cell_type":"code","source":["units = [[128,128],[128,128,128],[128,128,128],[256,256,128]]\n","dropout_rates = [0,0,0.05,0.05]\n","for u,dropout_rate in zip(units,dropout_rates):\n","        model = delayNNmodel(input_shape, hidden_units = u, dropout_rate = dropout_rate)\n","        print(\"units: {0}, dropout: {1}\".format(u,dropout_rate))\n","        fit_and_plot(model,X_train_balanced,Y_train_balanced,X_test,Y_test,verbose=False,epochs=10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"teKR8hBELxgc","colab_type":"code","colab":{}},"cell_type":"code","source":["units = [[128,128,128],[256,256,128]]\n","dropout_rates = [0,0.05]\n","for u,dropout_rate in zip(units,dropout_rates):\n","        model = delayNNmodel(input_shape, hidden_units = u, dropout_rate = dropout_rate)\n","        print(\"units: {0}, dropout: {1}\".format(u,dropout_rate))\n","        fit_and_plot(model,X_train_balanced,Y_train_balanced,X_test,Y_test,verbose=False,epochs=20)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"loPAqgc5Lxge","colab_type":"code","colab":{}},"cell_type":"code","source":["units = [[256,256,128]]\n","dropout_rates = [0.05]\n","for u,dropout_rate in zip(units,dropout_rates):\n","        model = delayNNmodel(input_shape, hidden_units = u, dropout_rate = dropout_rate)\n","        print(\"units: {0}, dropout: {1}\".format(u,dropout_rate))\n","        fit_and_plot(model,X_train_balanced,Y_train_balanced,X_test,Y_test,verbose=False,epochs=40)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JoKrNVn2Lxgg","colab_type":"code","colab":{}},"cell_type":"code","source":["units = [[256,256,128]]\n","input_shape = [X_train.shape[1]]\n","dropout_rates = [0.05]\n","for u,dropout_rate in zip(units,dropout_rates):\n","        model = delayNNmodel(input_shape, hidden_units = u, dropout_rate = dropout_rate)\n","        print(\"units: {0}, dropout: {1}\".format(u,dropout_rate))\n","        fitted_model = fit_and_plot(model,X_train_balanced,Y_train_balanced,X_test,Y_test,verbose=False,epochs=80,\n","                                    evaluate_offset=30)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zNraXJBwLxgi","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}