{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"notebook_6_text_clustering.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"dEaycuZuj3Lj","colab_type":"text"},"cell_type":"markdown","source":["# 1 Introduction\n","\n","Our dataset is a set of questions from  the online forum [Stack Exchange](https://stackexchange.com/). Every row has three columns:\n"," \n"," 1. title of the question\n"," 2. content of the question in HTML format\n"," 3. some tags related to the question\n"," \n","We will focus only on the content column. We will try to cluster the documents in a meaningful way so that we can identify similar documents and find groups of related subjects.\n","\n","The data was found on [Kaggle](https://www.kaggle.com/akshatpathak/text-data-clustering/data). Don't go looking now, because on the webpage it is already splitted into categories. In this exercise, it is the goal to cluster the documents and to find meaningful clusters ourselves, in a unsupervised way.  The data has been merged and mixed.\n"," "]},{"metadata":{"id":"wkW58dRmlWB-","colab_type":"text"},"cell_type":"markdown","source":["# 2 Exploring and preparing the data"]},{"metadata":{"id":"OFhuqDrCl1vW","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BIlReUuljsfq","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import time\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hwcvzpQNlrIc","colab_type":"code","colab":{}},"cell_type":"code","source":["questions = pd.read_csv(\"/content/drive/My Drive/xylosai/clustering/questionData.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IAix_G1Ww2kM","colab_type":"code","colab":{}},"cell_type":"code","source":["len(questions)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A8KU6LGymdP3","colab_type":"code","colab":{}},"cell_type":"code","source":["questions.head(10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z6vqhsA1mpq0","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"H9w3BgXjmezW","colab_type":"code","colab":{}},"cell_type":"code","source":["questions.drop(columns=[\"title\",\"tags\"],inplace=True)\n","questions.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kXhCemrHmx73","colab_type":"code","colab":{}},"cell_type":"code","source":["for question in questions[\"content\"][0:10]:\n","  print(question)\n","  print(\"***\"*30)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6YafGYcwnxoO","colab_type":"text"},"cell_type":"markdown","source":["The content is in HTML format with a lot of tags like `` <p></p> or <a></a> ``. We need to extract only the real text from the content body. For this, we use the get_text() method of the BeautifulSoup library."]},{"metadata":{"id":"NHFa2oLeCJXL","colab_type":"code","colab":{}},"cell_type":"code","source":["! pip install beautifulsoup4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mlUxnrfeoYLC","colab_type":"code","colab":{}},"cell_type":"code","source":["from bs4 import BeautifulSoup"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ybZ07r06ECKO","colab_type":"text"},"cell_type":"markdown","source":["Let's test on one example"]},{"metadata":{"colab_type":"code","id":"yqvrqqrHlnm5","colab":{}},"cell_type":"code","source":["print(questions[\"content\"][0])\n","print(\"***\"*30)\n","print(questions[\"content\"][6])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v8vSXmApC3TP","colab_type":"code","colab":{}},"cell_type":"code","source":["print(BeautifulSoup(questions[\"content\"][0]).get_text())\n","print(\"***\"*30)\n","print(BeautifulSoup(questions[\"content\"][6]).get_text()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cfdPW5n9JWtd","colab_type":"text"},"cell_type":"markdown","source":["Let's now apply this on all rows. "]},{"metadata":{"id":"FpwKQoBDJeCG","colab_type":"code","colab":{}},"cell_type":"code","source":["start = time.time()\n","questions[\"content_clean\"] = questions[\"content\"].apply(lambda x: BeautifulSoup(x).get_text())\n","end = time.time()\n","print(\"operation took {0} seconds\".format(end-start))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IoR9kBBMJrA5","colab_type":"code","colab":{}},"cell_type":"code","source":["questions.head()  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zCPlueylr5zi","colab_type":"text"},"cell_type":"markdown","source":["\n","# 3 Building the TF-IDF vectors\n","\n","Sklearn has built-in functionality for calculating TF-IDF vectors. [The documentation is found here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n","\n","Read the documentation. Look a the different parameters and decide which ones are relevant and which ones you don't really care about. Are we going to accept the defaults or do we need to change some parameter values?\n","\n","\n","It is clear that Sklearn builds the vocabulary (the list of all available words) automatically, if no vocabulary is given by the user. For this exercise, we will let Sklearn clear the job for us. \n","\n","Scroll down in the documentation and watch the available methods that we can call on the *TfidfVectorizer* object. Follow the links to get more details about the usage of a method. \n","\n","the *TfidfVectorizer* object is created with the parameters and fitted with the *fit()* method. When calling *fit()*, the object will internally build the IDF vector. This is the vector we need to transform a word count vector to a TF-IDF vector by multiplying elementwise. After fitting, any word count vector can be transformed into its corresponding TF-IDF vector, using the *transform()* method. \n","\n","The creation of a vocabulary, getting the word counts and calculating the IDF vector are completely abstracted away and handled by Sklearn in the background.\n","\n","\n","When calling *transform()*, a list of text objects is transformed into a TF-IDF weighted matrix of , with a row vector for each document.  These vectors and then used for the clustering\n"]},{"metadata":{"id":"3M2d1qxdKkPA","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"htJkgBJ7MoXQ","colab_type":"text"},"cell_type":"markdown","source":["We use all default values, except for min_df and max_df. With this setting, we will ignore all words that appear in less than 0.1% of the documents or that appear in more than 99% of the documents. "]},{"metadata":{"id":"eO17yFTdLiYu","colab_type":"code","colab":{}},"cell_type":"code","source":["vectorizer = TfidfVectorizer(min_df=0.001, max_df=0.99) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"j8OwGdkFL1PG","colab_type":"code","colab":{}},"cell_type":"code","source":["vectorizer.fit(questions[\"content_clean\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q5xoF8h1NpPN","colab_type":"text"},"cell_type":"markdown","source":["We can view our vocabulary with *get_feature_names()*. The first few features are just numbers, after that we get words. If we wanted to, we could tweak the model further so that we have no numbers as features."]},{"metadata":{"id":"kSVtehQ3MCnt","colab_type":"code","colab":{}},"cell_type":"code","source":["print(vectorizer.get_feature_names())\n","print(\"size of vocabulary: {0}\".format(len(vectorizer.get_feature_names())))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"78rrdoLWMMxX","colab_type":"code","colab":{}},"cell_type":"code","source":["feature_matrix = vectorizer.transform(questions[\"content_clean\"]) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"obBvnhd1OQgJ","colab_type":"text"},"cell_type":"markdown","source":["The result is a Scipy sparse matrix object. It behaves similar like a Numpy array, but it is optimized specifically for sparse matrices. \n","\n","Does the shape of the matrix make sense?"]},{"metadata":{"id":"hepnxYRBOGfe","colab_type":"code","colab":{}},"cell_type":"code","source":["print(type(feature_matrix))\n","print(feature_matrix.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eYIZTX8YP19i","colab_type":"text"},"cell_type":"markdown","source":["# 4 Clustering\n","\n","Sklearn supports various clustering algorithms [(see documentation here)](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster)"]},{"metadata":{"id":"HXlUF8IkQKgJ","colab_type":"text"},"cell_type":"markdown","source":["## 4.1 K-means\n","\n","First, we will try K-means. For this algorithm, we must decide in advance the number of clusters we want to find. We use the MiniBatchKMeans function. This is basically the same as KMeans, except that it updates the center positions incrementally using small batches of the data, instead of doing a clustering of all data examples in one large batch. \n","\n","For a large number of samples, this is much faster. Check yourself by replacing MiniBatchKMeans by KMeans. When using KMeans, the fitting takes very long."]},{"metadata":{"id":"ouCX6H8SUqBL","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.cluster import MiniBatchKMeans, KMeans"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I2WLk3p8P0aR","colab_type":"code","colab":{}},"cell_type":"code","source":["kmeans = MiniBatchKMeans(n_clusters = 4,random_state=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E7whA78UWUQv","colab_type":"text"},"cell_type":"markdown","source":["This could take a while..."]},{"metadata":{"id":"HvGV7N4NOlAw","colab_type":"code","colab":{}},"cell_type":"code","source":["cluster_labels = kmeans.fit_predict(feature_matrix)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-vaY-RwoVb1z","colab_type":"code","colab":{}},"cell_type":"code","source":["cluster_labels.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_LyYozKwYHB5","colab_type":"code","colab":{}},"cell_type":"code","source":["print(cluster_labels)\n","print(\"unique labels: {0}\".format(np.unique(cluster_labels)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OlKsPpOxYAnh","colab_type":"text"},"cell_type":"markdown","source":["We now have a list of cluster labels that map every original question to a cluster label. Since we have not named the clusters, they get a label of 0 to 4.\n","\n","We add the cluster labels as a column to our original questions dataframe. Then we filter the dataframe in order to display the four clusters."]},{"metadata":{"id":"36V79-vDXo4S","colab_type":"code","colab":{}},"cell_type":"code","source":["label_series = pd.Series(cluster_labels)\n","questions[\"label\"] = label_series"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_SjVwtgPZFhI","colab_type":"code","colab":{}},"cell_type":"code","source":["questions[\"label\"].unique()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ffhpFVH3Y_GK","colab_type":"code","colab":{}},"cell_type":"code","source":["questions.head(10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nb7OVUbCZBi7","colab_type":"code","colab":{}},"cell_type":"code","source":["for label in questions[\"label\"].unique():\n","  print(\"First 10 samples of cluster {0}\".format(label))\n","  samples = questions[questions[\"label\"] == label][\"content_clean\"][0:10]\n","  print(samples)\n","  \n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zHxVOe2SZ5FK","colab_type":"text"},"cell_type":"markdown","source":["Do these clusterings seem accurate? Let's try with a different amount of clusters"]},{"metadata":{"id":"P-v8Yn3gZpOf","colab_type":"code","colab":{}},"cell_type":"code","source":["kmeans = MiniBatchKMeans(n_clusters = 6,random_state=0)\n","cluster_labels = kmeans.fit_predict(feature_matrix)\n","label_series = pd.Series(cluster_labels)\n","questions[\"label_6clusters\"] = label_series"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4dyIoSHRaPNH","colab_type":"code","colab":{}},"cell_type":"code","source":["for label in questions[\"label_6clusters\"].unique():\n","  print(\"First 10 samples of cluster {0}\".format(label))\n","  samples = questions[questions[\"label_6clusters\"] == label][\"content_clean\"][0:10]\n","  print(samples)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NjyrB60jbWal","colab_type":"text"},"cell_type":"markdown","source":["The original data came from 6 distinct classes: biology, cooking, crypto, DIY, robotics and travel. So it should be no surprise that clustering with 6 classes yields better results than 4 classes.\n","\n","It looks like...\n","* cluster 0 is about DIY. \n","* Cluster 1 is about cooking. \n","* Cluster 2 is about travelling\n","* Cluster 3 has only one sample\n","* Cluster 4 and 5 are not clear, they appear to be a mix of many\n","\n","\n","\n"]},{"metadata":{"id":"Q_1KudvTfJYo","colab_type":"text"},"cell_type":"markdown","source":["## 4.2 Mean-shift\n","\n","Instead of first creating a clustering class (MeanShift class), and then calling a *fit()* function on it, we will directly use a function called *mean_shift()*. \n","\n","This would also have been possible for K-means, using the *k_means()* function. The options are clear when [reading the docs, where an overview of both classes and functions is given ](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster).\n","\n","By the way...\n","\n","[read the docs for mean_shift()!](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.mean_shift.html#sklearn.cluster.mean_shift)"]},{"metadata":{"id":"S4PeZGnyfLws","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.cluster import mean_shift"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yfXXdY5Phyhl","colab_type":"text"},"cell_type":"markdown","source":["Running the cell below takes forever. It is clear that mean-shift is computationally more expensive."]},{"metadata":{"id":"vaa7Rxb6frjz","colab_type":"code","colab":{}},"cell_type":"code","source":["cluster_centers, labels = mean_shift(feature_matrix.toarray(),n_jobs=-1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Kk48o0PgFch","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}